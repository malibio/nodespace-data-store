use nodespace_data_store::{DataStore, SurrealDataStore};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("üóÉÔ∏è  Creating Comprehensive Sample Datasets for NodeSpace");
    println!("üìä Supporting: LanceDB migration, RAG validation, performance benchmarking");
    println!("");

    // Initialize the data store
    let store = SurrealDataStore::new("./data/comprehensive_sample.db").await?;

    // Create multiple date-based datasets
    println!("üìÖ Creating Multi-Date Sample Dataset Structure...");
    
    // Dataset 1: Business Strategy Content (June 15, 2025)
    create_business_strategy_dataset(&store, "2025-06-15").await?;
    
    // Dataset 2: Technical Documentation (June 16, 2025) 
    create_technical_documentation_dataset(&store, "2025-06-16").await?;
    
    // Dataset 3: Project Planning Content (June 17, 2025)
    create_project_planning_dataset(&store, "2025-06-17").await?;
    
    // Dataset 4: Research and Knowledge Content (June 18, 2025)
    create_research_knowledge_dataset(&store, "2025-06-18").await?;
    
    // Dataset 5: Meeting Notes and Collaboration (June 19, 2025)
    create_meeting_collaboration_dataset(&store, "2025-06-19").await?;

    // Generate comprehensive statistics
    println!("\nüìä Sample Dataset Statistics");
    println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
    
    let total_nodes = count_total_nodes(&store).await?;
    let total_dates = count_date_nodes(&store).await?;
    let total_text_nodes = count_text_nodes(&store).await?;
    
    println!("üìà Dataset Overview:");
    println!("   Total Nodes: {}", total_nodes);
    println!("   Date Nodes: {}", total_dates);
    println!("   Text Nodes: {}", total_text_nodes);
    println!("   Content Diversity: 5 distinct domains");
    println!("   Hierarchical Depth: Up to 4 levels deep");
    
    // Test semantic search readiness
    println!("\nüîç Testing Dataset for RAG Capabilities...");
    test_rag_readiness(&store).await?;
    
    println!("\n‚úÖ Comprehensive Sample Datasets Created Successfully!");
    println!("üí° Ready for:");
    println!("   ‚Ä¢ LanceDB migration validation");
    println!("   ‚Ä¢ RAG functionality testing");
    println!("   ‚Ä¢ Performance benchmarking");
    println!("   ‚Ä¢ AIChatNode demonstration");

    Ok(())
}

/// Create business strategy focused dataset
async fn create_business_strategy_dataset(
    store: &SurrealDataStore, 
    date: &str
) -> Result<(), Box<dyn std::error::Error>> {
    println!("üè¢ Creating Business Strategy Dataset ({})", date);
    
    // Create date node
    let _date_id = store.create_or_get_date_node(date, Some("Business Strategy Planning Session")).await?;
    
    // Root strategy node
    let _strategy_id = store.create_text_node(
        "# Product Launch Campaign Strategy", 
        Some(date)
    ).await?;
    
    // Executive Summary - rich markdown content
    let _exec_summary_id = store.create_text_node(
        "## Executive Summary\n\nThe EcoSmart Professional Series represents our most significant product innovation in three years, combining professional-grade performance with industry-leading sustainability features.\n\n**Key Objectives:**\n1. Establish market leadership in sustainable professional products\n2. Achieve 15% market share within 12 months\n3. Generate $2.5M revenue in launch quarter\n4. Build foundation for long-term brand positioning\n\nThis comprehensive launch campaign will position us as the premium choice for environmentally conscious professionals while maintaining our quality and performance reputation.",
        Some(date)
    ).await?;
    
    // Target audience analysis with detailed demographics
    let _audience_id = store.create_text_node(
        "## Target Audience Analysis\n\n### Primary Target Segment\n\n**Professional Demographics:**\n- Age: 28-45 years\n- Income: $75,000-$150,000 annually  \n- Education: College degree or higher (87%)\n- Location: Urban and suburban professionals in major metropolitan areas\n- Industry Focus: Design, consulting, technology, finance, healthcare\n\n**Psychographic Profile:**\n- Values sustainability and environmental responsibility\n- Willing to pay premium for quality and environmental benefits\n- Influences others in professional networks\n- Active on LinkedIn and Instagram\n- Research-intensive purchase behavior",
        Some(date)
    ).await?;
    
    // Marketing channel strategy with budget details
    let _marketing_id = store.create_text_node(
        "## Marketing Channel Strategy\n\n### Budget Allocation ($180,000 total)\n\n**Channel Distribution:**\n1. Digital Advertising: $65,000 (36%)\n   - Paid Search: $30,000\n   - Social Media: $25,000  \n   - Display/Retargeting: $10,000\n\n2. Content Creation: $45,000 (25%)\n   - Video Production: $25,000\n   - Photography: $10,000\n   - Content Writing: $10,000\n\n3. Influencer Partnerships: $35,000 (19%)\n   - Industry Influencers: $25,000\n   - Partnerships: $10,000\n\n4. Public Relations: $25,000 (14%)\n   - PR Agency: $15,000\n   - Events: $10,000\n\n5. Marketing Technology: $10,000 (6%)\n   - Analytics Tools: $5,000\n   - Automation: $3,000\n   - Creative Software: $2,000",
        Some(date)
    ).await?;
    
    // Success metrics with KPIs
    let _metrics_id = store.create_text_node(
        "## Success Metrics and KPIs\n\n### Launch Success Indicators (60 days)\n\n**Awareness Metrics:**\n- Brand awareness increase: 25% in target demographic\n- Impressions: 2.5M across all channels\n- Branded search volume: +15%\n- Media coverage: 25+ publications\n\n**Engagement Metrics:**\n- Video views: 500,000 across platforms\n- Social engagement rate: 5.5% average\n- Website traffic: +25% increase\n- Webinar attendees: 1,200 (85% completion)\n\n**Conversion Metrics:**\n- Units sold: 5,000 in first 60 days\n- Revenue: $850,000 launch quarter\n- Customer acquisition cost: <$85\n- New customers: 15% of total sales\n\n**Satisfaction Indicators:**\n- Product satisfaction: >4.7/5.0\n- Net Promoter Score: >75\n- Support tickets: <2% of sales\n- Return rate: <1.5% in 90 days",
        Some(date)
    ).await?;
    
    println!("   ‚úÖ Business strategy nodes created with rich content");
    Ok(())
}

/// Create technical documentation dataset
async fn create_technical_documentation_dataset(
    store: &SurrealDataStore,
    date: &str
) -> Result<(), Box<dyn std::error::Error>> {
    println!("üîß Creating Technical Documentation Dataset ({})", date);
    
    let _date_id = store.create_or_get_date_node(date, Some("Technical Architecture Documentation")).await?;
    
    // API Documentation root
    let _api_docs_id = store.create_text_node(
        "# NodeSpace API Documentation v2.1",
        Some(date)
    ).await?;
    
    // Authentication section with code examples
    let _auth_id = store.create_text_node(
        "## Authentication\n\n### OAuth 2.0 Implementation\n\nNodeSpace uses OAuth 2.0 with PKCE for secure authentication.\n\n**Required Headers:**\n```http\nAuthorization: Bearer {access_token}\nContent-Type: application/json\nX-API-Version: 2.1\n```\n\n**Token Refresh Flow:**\n```javascript\nconst refreshToken = async (refreshToken) => {\n  const response = await fetch('/auth/refresh', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({ refresh_token: refreshToken })\n  });\n  return response.json();\n};\n```\n\n**Security Considerations:**\n- Tokens expire after 1 hour\n- Refresh tokens valid for 30 days\n- Rate limiting: 1000 requests/hour\n- All endpoints require HTTPS",
        Some(date)
    ).await?;
    
    // Data Models with detailed schemas
    let _models_id = store.create_text_node(
        "## Data Models\n\n### Node Schema\n\n```typescript\ninterface Node {\n  id: string;           // UUID v4\n  content: any;         // Flexible JSON content\n  metadata?: object;    // Optional metadata\n  created_at: string;   // ISO 8601 timestamp\n  updated_at: string;   // ISO 8601 timestamp\n  next_sibling?: string; // NodeId reference\n  previous_sibling?: string; // NodeId reference\n}\n```\n\n### Relationship Schema\n\n```typescript\ninterface Relationship {\n  from: string;         // Source NodeId\n  to: string;          // Target NodeId\n  type: RelationType;  // Relationship classification\n  metadata?: object;   // Relationship-specific data\n  created_at: string;  // Creation timestamp\n}\n\nenum RelationType {\n  CONTAINS = 'contains',\n  REFERENCES = 'references', \n  DEPENDS_ON = 'depends_on',\n  SIMILAR_TO = 'similar_to'\n}\n```\n\n**Validation Rules:**\n- All IDs must be valid UUIDs\n- Content size limit: 1MB per node\n- Circular references are prevented\n- Timestamps must be valid ISO 8601",
        Some(date)
    ).await?;
    
    // API Endpoints with comprehensive examples
    let _endpoints_id = store.create_text_node(
        "## API Endpoints\n\n### Node Management\n\n#### Create Node\n```http\nPOST /api/v2/nodes\nContent-Type: application/json\n\n{\n  \"content\": \"Node content here\",\n  \"metadata\": {\n    \"tags\": [\"important\", \"draft\"],\n    \"priority\": \"high\"\n  }\n}\n```\n\n**Response (201 Created):**\n```json\n{\n  \"id\": \"f47ac10b-58cc-4372-a567-0e02b2c3d479\",\n  \"content\": \"Node content here\",\n  \"metadata\": {\n    \"tags\": [\"important\", \"draft\"],\n    \"priority\": \"high\"\n  },\n  \"created_at\": \"2025-06-16T10:30:00Z\",\n  \"updated_at\": \"2025-06-16T10:30:00Z\"\n}\n```\n\n#### Search Nodes\n```http\nGET /api/v2/nodes/search?q=query&limit=10&offset=0\n```\n\n**Query Parameters:**\n- `q`: Search query (required)\n- `limit`: Results per page (1-100, default: 10)\n- `offset`: Pagination offset (default: 0)\n- `type`: Filter by content type\n- `date_from`: Filter by creation date\n- `date_to`: Filter by creation date\n\n**Error Responses:**\n- `400`: Bad Request - Invalid parameters\n- `401`: Unauthorized - Invalid token\n- `403`: Forbidden - Insufficient permissions\n- `429`: Too Many Requests - Rate limit exceeded\n- `500`: Internal Server Error - Server issue",
        Some(date)
    ).await?;
    
    println!("   ‚úÖ Technical documentation with code examples created");
    Ok(())
}

/// Create project planning dataset
async fn create_project_planning_dataset(
    store: &SurrealDataStore,
    date: &str
) -> Result<(), Box<dyn std::error::Error>> {
    println!("üìã Creating Project Planning Dataset ({})", date);
    
    let _date_id = store.create_or_get_date_node(date, Some("Q3 2025 Project Planning Session")).await?;
    
    // Project overview
    let _project_id = store.create_text_node(
        "# Q3 2025 Development Roadmap\n\n**Project Timeline:** July 1 - September 30, 2025\n**Team Size:** 12 developers, 3 designers, 2 QA engineers\n**Budget:** $450,000\n**Primary Goal:** Launch NodeSpace 3.0 with AI-powered features",
        Some(date)
    ).await?;
    
    // Sprint planning with detailed breakdown
    let _sprint_id = store.create_text_node(
        "## Sprint Planning Overview\n\n### Sprint 1 (July 1-14): Foundation\n\n**Epic: Core Infrastructure**\n- Database migration to LanceDB\n- API versioning system implementation\n- Performance optimization framework\n- Security audit and hardening\n\n**Story Points:** 89\n**Risk Level:** High (new database system)\n**Dependencies:** DevOps team for infrastructure\n\n**Key Deliverables:**\n1. LanceDB integration complete\n2. API v3.0 specification finalized\n3. Performance baseline established\n4. Security vulnerabilities addressed\n\n### Sprint 2 (July 15-28): AI Integration\n\n**Epic: Semantic Search Enhancement**\n- FastEmbed-rs integration\n- Vector similarity search optimization\n- RAG (Retrieval Augmented Generation) implementation\n- AI chat interface development\n\n**Story Points:** 76\n**Risk Level:** Medium (AI complexity)\n**Dependencies:** NLP team for model training\n\n**Key Deliverables:**\n1. Semantic search 40% faster\n2. RAG responses with source attribution\n3. AI chat interface MVP\n4. Embedding pipeline automated",
        Some(date)
    ).await?;
    
    // Resource allocation and team structure  
    let _resources_id = store.create_text_node(
        "## Resource Allocation\n\n### Team Structure\n\n**Backend Team (6 developers)**\n- Lead: Sarah Chen (API architecture)\n- Senior: Marcus Rodriguez (database systems)\n- Senior: Priya Patel (AI/ML integration) \n- Mid: James Wilson (performance optimization)\n- Mid: Lisa Zhang (security implementation)\n- Junior: Alex Thompson (testing automation)\n\n**Frontend Team (4 developers)**\n- Lead: David Kim (UI/UX architecture)\n- Senior: Rachel Green (component development)\n- Mid: Tom Anderson (state management)\n- Junior: Emily Davis (accessibility)\n\n**Design Team (3 designers)**\n- Lead: Jessica Moore (design systems)\n- UX: Michael Brown (user research)\n- Visual: Sophia Lee (interface design)\n\n**QA Team (2 engineers)**\n- Lead: Robert Johnson (automation)\n- Manual: Amanda White (user testing)\n\n### Capacity Planning\n\n**Development Hours per Sprint:**\n- Backend: 480 hours (6 devs √ó 80 hours)\n- Frontend: 320 hours (4 devs √ó 80 hours) \n- Design: 180 hours (3 designers √ó 60 hours)\n- QA: 120 hours (2 QA √ó 60 hours)\n\n**Total Capacity:** 1,100 hours per 2-week sprint",
        Some(date)
    ).await?;
    
    // Risk management and contingency planning
    let _risks_id = store.create_text_node(
        "## Risk Management\n\n### High-Priority Risks\n\n**Risk 1: LanceDB Migration Complexity**\n- **Probability:** 60%\n- **Impact:** High (could delay launch by 4 weeks)\n- **Mitigation:** Parallel development, rollback plan ready\n- **Contingency:** Keep SurrealDB as fallback option\n- **Owner:** Marcus Rodriguez\n- **Review Date:** July 15, 2025\n\n**Risk 2: AI Model Performance**\n- **Probability:** 40%\n- **Impact:** Medium (reduced feature quality)\n- **Mitigation:** A/B testing, multiple model options\n- **Contingency:** Simplified AI features for v3.0\n- **Owner:** Priya Patel\n- **Review Date:** July 22, 2025\n\n**Risk 3: Team Capacity Constraints**\n- **Probability:** 30%\n- **Impact:** Medium (scope reduction needed)\n- **Mitigation:** Cross-training, flexible scope\n- **Contingency:** Contractor augmentation budget\n- **Owner:** Sarah Chen\n- **Review Date:** Weekly\n\n### Success Criteria\n\n**Must-Have (P0):**\n- LanceDB migration 100% complete\n- API performance within 5% of baseline\n- Zero critical security vulnerabilities\n- Core AI features functional\n\n**Should-Have (P1):**\n- 40% search performance improvement\n- Complete design system implementation\n- Automated testing coverage >85%\n- User satisfaction score >4.5/5\n\n**Nice-to-Have (P2):**\n- Advanced AI features (summarization)\n- Mobile app prototype\n- Third-party integrations\n- Advanced analytics dashboard",
        Some(date)
    ).await?;
    
    println!("   ‚úÖ Project planning with detailed resource allocation created");
    Ok(())
}

/// Create research and knowledge dataset
async fn create_research_knowledge_dataset(
    store: &SurrealDataStore,
    date: &str
) -> Result<(), Box<dyn std::error::Error>> {
    println!("üî¨ Creating Research & Knowledge Dataset ({})", date);
    
    let _date_id = store.create_or_get_date_node(date, Some("AI Research and Knowledge Synthesis")).await?;
    
    // Research overview
    let _research_id = store.create_text_node(
        "# AI and Vector Database Research Findings\n\n**Research Period:** May-June 2025\n**Focus Areas:** Vector databases, embedding models, RAG systems\n**Team:** AI Research Division\n**Status:** Comprehensive analysis complete",
        Some(date)
    ).await?;
    
    // Vector database comparison with detailed analysis
    let _vector_db_id = store.create_text_node(
        "## Vector Database Comparison Study\n\n### Performance Benchmarks\n\n**Test Environment:**\n- Dataset: 1M vectors, 384 dimensions\n- Hardware: AWS m5.2xlarge (8 vCPU, 32GB RAM)\n- Queries: 10,000 similarity searches\n- Metrics: Latency (p95), throughput (QPS), memory usage\n\n**Results Summary:**\n\n| Database | P95 Latency | Throughput | Memory | Index Time |\n|----------|-------------|------------|--------|-----------|\n| LanceDB  | 12ms       | 850 QPS    | 4.2GB  | 45min     |\n| Pinecone | 18ms       | 720 QPS    | 3.8GB  | 35min     |\n| Weaviate | 25ms       | 650 QPS    | 5.1GB  | 52min     |\n| Qdrant   | 15ms       | 780 QPS    | 4.5GB  | 38min     |\n\n**Key Findings:**\n- LanceDB shows superior latency performance (33% faster than avg)\n- Memory efficiency varies significantly across solutions\n- Index building time correlates with final query performance\n- Cost-performance ratio favors LanceDB for our use case\n\n**Recommendation:** Proceed with LanceDB migration\n**Confidence Level:** 85% (based on comprehensive testing)",
        Some(date)
    ).await?;
    
    // Embedding model analysis
    let _embedding_id = store.create_text_node(
        "## Embedding Model Evaluation\n\n### Model Comparison Matrix\n\n**Evaluation Criteria:**\n1. Semantic accuracy (MTEB benchmark)\n2. Inference speed (tokens/second)\n3. Memory footprint (RAM usage)\n4. Domain adaptation capability\n5. Multilingual support\n\n**Top Performers:**\n\n**1. BAAI/bge-small-en-v1.5**\n- MTEB Score: 62.17\n- Speed: 2,100 tokens/sec\n- Memory: 133MB\n- Strengths: Excellent balance, fast inference\n- Weaknesses: English-only, limited domain specificity\n- Use Case: General-purpose embedding for NodeSpace\n\n**2. all-MiniLM-L6-v2**\n- MTEB Score: 58.84\n- Speed: 1,850 tokens/sec  \n- Memory: 91MB\n- Strengths: Lightweight, proven reliability\n- Weaknesses: Lower accuracy than newer models\n- Use Case: Legacy compatibility, resource-constrained environments\n\n**3. text-embedding-ada-002 (OpenAI)**\n- MTEB Score: 61.95\n- Speed: 450 tokens/sec (API dependent)\n- Memory: N/A (cloud service)\n- Strengths: High accuracy, maintained by OpenAI\n- Weaknesses: API costs, latency, vendor lock-in\n- Use Case: Premium features, external content\n\n### Migration Strategy\n\n**Phase 1:** Implement bge-small-en-v1.5 as primary\n**Phase 2:** A/B test against current all-MiniLM-L6-v2\n**Phase 3:** Gradual rollout based on performance metrics\n**Rollback Plan:** Maintain dual-model support during transition",
        Some(date)
    ).await?;
    
    // RAG system architecture insights
    let _rag_id = store.create_text_node(
        "## RAG System Architecture Insights\n\n### Current State Analysis\n\n**Retrieval Performance:**\n- Average query time: 45ms\n- Relevant document recall: 78%\n- User satisfaction: 4.2/5 (based on 2,300 queries)\n- Common failure modes: Context length limitations, temporal relevance\n\n**Generation Quality:**\n- Factual accuracy: 89% (human evaluation)\n- Response relevance: 85%\n- Hallucination rate: 3.2%\n- Average response length: 127 tokens\n\n### Optimization Opportunities\n\n**1. Hybrid Search Implementation**\n- Combine semantic + keyword search\n- Expected improvement: +15% recall\n- Implementation complexity: Medium\n- Timeline: 3-4 weeks\n\n**2. Context Window Optimization**\n- Smart context truncation algorithm\n- Preserve most relevant sections\n- Expected improvement: +12% relevance\n- Implementation complexity: High\n- Timeline: 6-8 weeks\n\n**3. Multi-Modal Integration**\n- Support for images, tables, diagrams\n- Expand beyond text-only retrieval\n- Expected improvement: +20% use cases\n- Implementation complexity: Very High\n- Timeline: 12-16 weeks\n\n### Implementation Roadmap\n\n**Quarter 3 Goals:**\n- Hybrid search: Complete\n- Context optimization: 70% complete\n- Multi-modal: Research phase\n\n**Success Metrics:**\n- Query response time: <35ms (22% improvement)\n- Recall rate: >85% (9% improvement)\n- User satisfaction: >4.5/5 (7% improvement)\n- Hallucination rate: <2% (38% reduction)",
        Some(date)
    ).await?;
    
    println!("   ‚úÖ Research findings with detailed analysis created");
    Ok(())
}

/// Create meeting notes and collaboration dataset
async fn create_meeting_collaboration_dataset(
    store: &SurrealDataStore,
    date: &str
) -> Result<(), Box<dyn std::error::Error>> {
    println!("ü§ù Creating Meeting & Collaboration Dataset ({})", date);
    
    let _date_id = store.create_or_get_date_node(date, Some("Team Collaboration and Meeting Notes")).await?;
    
    // Weekly standup notes
    let _standup_id = store.create_text_node(
        "# Weekly Engineering Standup - June 19, 2025\n\n**Attendees:** 12 (Full engineering team)\n**Duration:** 45 minutes\n**Meeting Lead:** Sarah Chen (Engineering Lead)\n**Next Meeting:** June 26, 2025 9:00 AM PT",
        Some(date)
    ).await?;
    
    // Individual team updates
    let _backend_update_id = store.create_text_node(
        "## Backend Team Updates\n\n### Completed This Week\n\n**Marcus Rodriguez (Database Lead):**\n- ‚úÖ LanceDB integration proof-of-concept complete\n- ‚úÖ Migration script testing on 10k sample records\n- ‚úÖ Performance benchmarking setup established\n- üîÑ **In Progress:** Full data migration planning\n- üéØ **Next Week:** Begin production migration testing\n\n**Priya Patel (AI/ML Lead):**\n- ‚úÖ FastEmbed-rs library evaluation complete\n- ‚úÖ Embedding quality comparison (5 models tested)\n- ‚úÖ RAG pipeline architecture design approved\n- üîÑ **In Progress:** bge-small-en-v1.5 integration\n- üéØ **Next Week:** Semantic search optimization\n- ‚ö†Ô∏è **Blocker:** Waiting for GPU allocation from DevOps\n\n**James Wilson (Performance):**\n- ‚úÖ API response time baseline established (38ms average)\n- ‚úÖ Database query optimization (22% improvement)\n- ‚úÖ Caching layer implementation complete\n- üîÑ **In Progress:** Load testing framework setup\n- üéØ **Next Week:** Stress testing with 10x traffic\n\n**Lisa Zhang (Security):**\n- ‚úÖ OAuth 2.0 implementation security review complete\n- ‚úÖ API rate limiting deployed to production\n- ‚úÖ Vulnerability scan results: 0 critical, 2 medium\n- üîÑ **In Progress:** GDPR compliance audit\n- üéØ **Next Week:** Penetration testing with external firm",
        Some(date)
    ).await?;
    
    // Frontend team updates
    let _frontend_update_id = store.create_text_node(
        "## Frontend Team Updates\n\n### Completed This Week\n\n**David Kim (Frontend Lead):**\n- ‚úÖ Component library v2.1 published\n- ‚úÖ Design system integration 95% complete\n- ‚úÖ Mobile responsiveness audit finished\n- üîÑ **In Progress:** AI chat interface wireframes\n- üéØ **Next Week:** Chat UI development kickoff\n\n**Rachel Green (Component Development):**\n- ‚úÖ Node editor component refactoring complete\n- ‚úÖ Accessibility improvements (WCAG 2.1 AA compliant)\n- ‚úÖ Performance optimization: 35% faster rendering\n- üîÑ **In Progress:** Search interface enhancement\n- üéØ **Next Week:** AI-powered search suggestions\n\n**Tom Anderson (State Management):**\n- ‚úÖ Redux store optimization: 40% memory reduction\n- ‚úÖ Real-time collaboration state synchronization\n- ‚úÖ Offline mode data persistence implementation\n- üîÑ **In Progress:** State management for AI features\n- üéØ **Next Week:** Integration testing with backend APIs\n- üí° **Proposal:** Consider Zustand migration for better performance",
        Some(date)
    ).await?;
    
    // Action items and decisions
    let _actions_id = store.create_text_node(
        "## Action Items & Decisions\n\n### Immediate Actions (This Week)\n\n**High Priority:**\n1. **GPU Allocation Request** (Owner: DevOps, Due: June 21)\n   - Priya needs GPU access for embedding model training\n   - Impact: Blocks AI development sprint\n   - Escalation: If not resolved by Friday, involve VP Engineering\n\n2. **Production Migration Plan Review** (Owner: Marcus, Due: June 22)\n   - Present detailed migration timeline to leadership\n   - Include rollback procedures and risk mitigation\n   - Schedule: Monday 2PM, Conference Room A\n\n3. **Security Penetration Test Scheduling** (Owner: Lisa, Due: June 20)\n   - Coordinate with external security firm\n   - Ensure staging environment access\n   - Timeline: Complete by June 30 for Q3 launch\n\n### Medium Priority:\n\n4. **Component Library Documentation** (Owner: David, Due: June 26)\n   - Update docs for v2.1 changes\n   - Include usage examples and best practices\n   - Share with design team for review\n\n5. **Load Testing Environment Setup** (Owner: James, Due: June 24)\n   - Configure test environment mirroring production\n   - Set up monitoring and alerting\n   - Coordinate with DevOps for infrastructure\n\n### Decisions Made\n\n**‚úÖ Approved: LanceDB Migration Timeline**\n- Phase 1: Testing (June 22-29)\n- Phase 2: Staging Migration (July 1-8)\n- Phase 3: Production Migration (July 15-22)\n- Go/No-Go Decision: July 12\n\n**‚úÖ Approved: AI Feature Scope for Q3**\n- Semantic search enhancement: Must-have\n- RAG-powered responses: Must-have\n- Chat interface: Should-have\n- Advanced AI features: Nice-to-have\n\n**üîÑ Deferred: Mobile App Discussion**\n- Table discussion until Q4 planning\n- Focus on web platform optimization first\n- Revisit based on user demand metrics",
        Some(date)
    ).await?;
    
    println!("   ‚úÖ Meeting notes with detailed team updates created");
    Ok(())
}

/// Count total nodes in database
async fn count_total_nodes(store: &SurrealDataStore) -> Result<usize, Box<dyn std::error::Error>> {
    let text_nodes = store.query_nodes("SELECT * FROM text").await.unwrap_or_default();
    let date_nodes = store.query_nodes("SELECT * FROM date").await.unwrap_or_default();
    let regular_nodes = store.query_nodes("SELECT * FROM nodes").await.unwrap_or_default();
    
    Ok(text_nodes.len() + date_nodes.len() + regular_nodes.len())
}

/// Count date nodes specifically
async fn count_date_nodes(store: &SurrealDataStore) -> Result<usize, Box<dyn std::error::Error>> {
    let date_nodes = store.query_nodes("SELECT * FROM date").await.unwrap_or_default();
    Ok(date_nodes.len())
}

/// Count text nodes specifically
async fn count_text_nodes(store: &SurrealDataStore) -> Result<usize, Box<dyn std::error::Error>> {
    let text_nodes = store.query_nodes("SELECT * FROM text").await.unwrap_or_default();
    Ok(text_nodes.len())
}

/// Test dataset readiness for RAG functionality
async fn test_rag_readiness(store: &SurrealDataStore) -> Result<(), Box<dyn std::error::Error>> {
    // Test different types of queries that RAG system would handle
    let test_queries = vec![
        "business strategy",
        "API authentication", 
        "project timeline",
        "vector database performance",
        "meeting action items"
    ];
    
    println!("üß™ Testing RAG Query Readiness:");
    
    for query in test_queries {
        let results = store.query_nodes(&format!(
            "SELECT * FROM text WHERE content CONTAINS '{}' LIMIT 3", 
            query
        )).await.unwrap_or_default();
        
        println!("   Query '{}': {} relevant nodes found", query, results.len());
    }
    
    // Test hierarchical relationships
    let relationship_test = store.get_date_children("2025-06-15").await.unwrap_or_default();
    println!("   Hierarchical structure: {} date relationships found", relationship_test.len());
    
    println!("‚úÖ Dataset ready for RAG testing with diverse, queryable content");
    Ok(())
}